{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Get the names of subdirectories (citys from which data was pulled from NREL)\n",
    "# in the \"/Data\" directory. Returns a list of these names.\n",
    "def get_folder_names(data_folder_path):\n",
    "    folder_names = [f for f in os.listdir(folder_path)\\\n",
    "        if not f.startswith('.')]\n",
    "    return folder_names\n",
    "\n",
    "# Turn a list of subdirectory names containing yearly csv data and a list of years into\n",
    "# a dictionary of dictionaries. Ex: {city1 : {year1 : year1.csv, year2 : year2.csv}, city2 : {year1 : year1.csv, year2 : year2.csv}}\n",
    "def data_dirs_2_csvdict(folder_path, folder_list, year_list):\n",
    "    csv_dict = {}\n",
    "    for folder in folder_list:\n",
    "        year_dict = {}\n",
    "        csv_list = [glob.glob(folder_path + '/{folder}/*_{year}.csv'.format(folder = folder, year = year))[0] for year in year_list]\n",
    "        for year, csv in zip(year_list,csv_list):\n",
    "            year_dict[year] = csv\n",
    "        csv_dict[folder] = year_dict\n",
    "    return csv_dict\n",
    "\n",
    "# Turn a dictionary of dictionaries of csv files into a dictionary of dictionaries of pd\n",
    "# dataframes\n",
    "def dict_2_pd_dict(city_year_dict):\n",
    "    df_dict = {}\n",
    "    for city in city_year_dict:\n",
    "        year_dict = {}\n",
    "        for year, csv in city_year_dict[city].items():\n",
    "            year_dict[year] = pd.read_csv(csv, header = 2)\n",
    "        df_dict[city] = year_dict\n",
    "    return df_dict\n",
    "\n",
    "# Take in a dictionary of dictionaries of data frames, and return the same thing but \n",
    "# with only select columns from each. Rename the columns to include the city.\n",
    "def select_cols(city_year_df_dict, col_names):\n",
    "    df_dict = {}\n",
    "    for city in city_year_df_dict:\n",
    "        year_dict = {}\n",
    "        for year, df in city_year_df_dict[city].items():\n",
    "            year_dict[year] = df[col_names]\n",
    "            new_cols = {}\n",
    "            for col in col_names:\n",
    "                new_cols[col] = '{city}_'.format(city=city) + col\n",
    "            year_dict[year].rename(columns = new_cols, inplace = True)\n",
    "        df_dict[city] = year_dict\n",
    "    return df_dict\n",
    "\n",
    "# Combine each year of data for a particular city into one data frame where the years\n",
    "# are stacked on top of one another\n",
    "def stack_years(city_year_df_dict):\n",
    "    df_dict = {}\n",
    "    for city in city_year_df_dict:\n",
    "        df_list = []\n",
    "        for df in city_year_df_dict[city].values():\n",
    "            df_list.append(df)\n",
    "        df_dict[city] = pd.concat(df_list, ignore_index=True)\n",
    "    return df_dict\n",
    "\n",
    "# Combine each city df horizontally to make one single df with the same number of rows, \n",
    "# but much \"wider\" now. \n",
    "def combine_cities(city_year_df_dict):\n",
    "    full_df = pd.DataFrame()\n",
    "    for df in city_year_df_dict.values():\n",
    "        full_df = pd.concat([full_df, df], axis=1)\n",
    "    return full_df\n",
    "\n",
    "# Eliminate all but one column for those with the same data.\n",
    "# Ex. Year, day, month...\n",
    "# Inputs are a dataframe, a list of strings of col type names to replace \n",
    "# eg. ['Year', 'Hour'] and a string of the city to keep.\n",
    "def one_col_keep(df, col_type_to_reduce, city_to_keep):\n",
    "    cols = list(df.columns)\n",
    "    cols_to_drop = []\n",
    "    rename_dict = {}\n",
    "    for col_type in col_type_to_reduce:\n",
    "        drop_candidates = [col for col in cols if col_type in col]\n",
    "        drop_list = [col for col in drop_candidates if city_to_keep not in col]\n",
    "        rename_list = [col for col in drop_candidates if city_to_keep in col]\n",
    "        if len(rename_list) == 1:\n",
    "            rename_dict[rename_list[0]] = col_type\n",
    "        elif len(rename_list) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            return Exception\n",
    "        cols_to_drop.extend(drop_list)\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    df = df.rename(columns = rename_dict)    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the month and day_of_month columns to a day_x and day_y\n",
    "# column. Where both have values in range [-1,1] by moving cw around\n",
    "# a unit circle where the top is Jan 1.\n",
    "def normalize_day_of_year(df, month_col, day_col):\n",
    "    month = df[month_col]\n",
    "    month = month.to_numpy()\n",
    "    day = df[day_col]\n",
    "    day = day.to_numpy()\n",
    "    month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    Day_X = np.zeros(len(month))\n",
    "    Day_Y = np.zeros(len(month))\n",
    "    for i in range(len(month)):\n",
    "        day_of_year = sum(month_days[:month[i]-1]) + day[i]\n",
    "        theta = 2 * math.pi * (day_of_year / 365)\n",
    "        Day_X[i] = math.sin(theta)\n",
    "        Day_Y[i] = math.cos(theta)\n",
    "    days_x_y = pd.DataFrame({'Day_X':Day_X, 'Day_Y':Day_Y})\n",
    "    df = pd.concat([days_x_y, df], axis=1)\n",
    "    df = df.drop([month_col, day_col], axis=1)\n",
    "    return df\n",
    "\n",
    "# Convert the hour and minute columns to a time_x and time_y\n",
    "# column. Where both have values in range [-1,1] by moving cw around\n",
    "# a unit circle where the top is midnight.\n",
    "def normalize_time_of_day(df, hour_col, minute_col):\n",
    "    hour = df[hour_col]\n",
    "    hour = hour.to_numpy()\n",
    "    minute = df[minute_col]\n",
    "    minute = minute.to_numpy()\n",
    "    min_of_day = 60 * hour + minute\n",
    "    Time_X = np.zeros(len(min_of_day))\n",
    "    Time_Y = np.zeros(len(min_of_day))\n",
    "    for i in range(len(min_of_day)):\n",
    "        theta = 2 * math.pi * (min_of_day[i] / 1440)\n",
    "        Time_X[i] = math.sin(theta)\n",
    "        Time_Y[i] = math.cos(theta)\n",
    "    time_x_y = pd.DataFrame({'Time_X':Time_X, 'Time_Y':Time_Y})\n",
    "    df = pd.concat([time_x_y, df], axis = 1)\n",
    "    df = df.drop([hour_col, minute_col], axis=1)\n",
    "    return df\n",
    "    \n",
    "# Replaces all wind speed and wind direction columns with cartesian coordinates\n",
    "# wind_x and wind_y\n",
    "def wind_polar_2_cart(df, city_list):\n",
    "    cols = list(df.columns)\n",
    "    for city in city_list:\n",
    "        w_speed_col = [col for col in cols if ((city in col) and ('Wind Speed' in col))]\n",
    "        w_direction_col = [col for col in cols if ((city in col) and ('Wind Direction' in col))]\n",
    "        if (len(w_speed_col) == 1 and len(w_direction_col)) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            return Exception\n",
    "        w_speed_col = w_speed_col[0]\n",
    "        w_direction_col = w_direction_col[0]\n",
    "        w_speed = df[w_speed_col]\n",
    "        w_direction = df[w_direction_col]\n",
    "        w_speed = w_speed.to_numpy()\n",
    "        w_direction = w_direction.to_numpy()\n",
    "        Wind_X = np.zeros(len(w_speed))\n",
    "        Wind_Y = np.zeros(len(w_speed))\n",
    "        for i in range(len(w_speed)):\n",
    "            w_direction_rad = math.radians(w_direction[i])\n",
    "            Wind_X[i] = w_speed[i] * math.sin(w_direction_rad)\n",
    "            Wind_Y[i] = w_speed[i] * math.cos(w_direction_rad)\n",
    "\n",
    "        wind_x_label = '{city}_Wind_X'.format(city=city)\n",
    "        wind_y_label = '{city}_Wind_Y'.format(city=city)\n",
    "        Wind_X = pd.DataFrame({wind_x_label:Wind_X})\n",
    "        Wind_Y = pd.DataFrame({wind_y_label:Wind_Y})\n",
    "\n",
    "        df[w_speed_col]=Wind_X[wind_x_label]\n",
    "        df[w_direction_col]=Wind_Y[wind_y_label]\n",
    "        df = df.rename(columns = {w_speed_col : wind_x_label, w_direction_col : wind_y_label})  \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local location of data files\n",
    "path = os.getcwd() + '/Data'\n",
    "\n",
    "# List of cities from which to get data (three letter abbreviation must match the name of the directory!)\n",
    "full_city_list = ['BUT', 'CBG', 'ELV', 'GRE', 'JON', 'KIT', 'MGT', 'NCS', 'NPH', 'PIT', 'PKS', 'STU', 'WAS', 'WHE', 'YGT']\n",
    "short_city_list = ['PIT', 'WAS', 'GRE', 'STU', 'ELV', 'KIT']\n",
    "PIT_only = ['PIT']\n",
    "\n",
    "'''\n",
    "full_city_data_csv_dict = data_dirs_2_csvdict(path, full_city_list, list(range(1998, 2020)))\n",
    "full_city_df_dict = dict_2_pd_dict(full_city_data_csv_dict)\n",
    "full_city_dict = select_cols(GHI_df_dict_train_val, ['Clearsky GHI'])\n",
    "GHI_dict = {}\n",
    "for city in GHI_dict_train_val:\n",
    "    df_list = []\n",
    "    for df in GHI_dict_train_val[city].values():\n",
    "        df_list.append(df)\n",
    "    GHI_dict[city] = pd.concat(df_list,axis = 1 )\n",
    "    GHI_dict[city][city + '_Clearsky_GHI_Max'] = GHI_dict[city].max(axis=1)\n",
    "    GHI_dict[city] = GHI_dict[city].drop([city + '_Clearsky GHI'], axis=1)\n",
    "GHI_train_dict = {}\n",
    "for city in GHI_dict:\n",
    "    GHI_train_dict[city] = pd.concat([GHI_dict[city], GHI_dict[city], GHI_dict[city]], ignore_index=True)\n",
    "\n",
    "GHI_val_dict = GHI_dict\n",
    "GHI_test_dict = GHI_dict\n",
    "'''\n",
    "\n",
    "city_lists = [full_city_list, short_city_list, PIT_only]\n",
    "\n",
    "for i in range(len(city_lists)):\n",
    "    \n",
    "    # Get csv files in a dictionary for all desired data\n",
    "    csv_dict = data_dirs_2_csvdict(path, city_lists[i], list(range(1998,2020)))\n",
    "\n",
    "    # Convert csv files into Pandas dataframes in a dictionary\n",
    "    df_dict = dict_2_pd_dict(csv_dict)\n",
    "\n",
    "    # complete list of columns (if desired at some point):\n",
    "    # #['Year','Month','Day','Hour','Minute','DHI','DNI','GHI','Clearsky DHI','Clearsky DNI','Clearsky GHI','Cloud Type', 'Dew Point', 'Solar Zenith', 'Surface Albedo', 'Wind Speed', 'Percipitable Water', 'Wind Direction', 'Relative Humidity', 'Temperature','Pressure','Global Horizontal UV Irradiance (280-400nm)', 'Global Horizontal UV Irradiance (295-385nm)']\n",
    "    desired_features = ['Month','Day','Hour','Minute','DHI','DNI','GHI','Clearsky DHI','Clearsky DNI','Clearsky GHI', 'Dew Point', 'Surface Albedo', 'Wind Speed', 'Wind Direction', 'Relative Humidity', 'Temperature','Pressure','Global Horizontal UV Irradiance (280-400nm)', 'Global Horizontal UV Irradiance (295-385nm)']\n",
    "\n",
    "    df_dict = select_cols(df_dict, desired_features)\n",
    "    df_dict = stack_years(df_dict)\n",
    "\n",
    "    df_full = combine_cities(df_dict)\n",
    "\n",
    "    df_full = one_col_keep(df_full, ['Month','Day','Hour','Minute'], 'PIT')\n",
    "\n",
    "    df_full = normalize_day_of_year(df_full, 'Month', 'Day')\n",
    "    df_full = normalize_time_of_day(df_full,'Hour', 'Minute')\n",
    "\n",
    "    df_full = wind_polar_2_cart(df_full, city_lists[i])\n",
    "        \n",
    "        \n",
    "    if i == 0:\n",
    "        df_full_cities = df_full\n",
    "\n",
    "    elif i == 1:\n",
    "        df_short_cities = df_full\n",
    "        \n",
    "    elif i == 2:\n",
    "        df_PIT = df_full\n",
    "\n",
    "full_cities_dict = {\n",
    "    'complete_data' : df_full_cities\n",
    "    }\n",
    "short_cities_dict = {\n",
    "    'complete_data' : df_short_cities\n",
    "}\n",
    "PIT_dict = {\n",
    "    'complete_data' : df_PIT\n",
    "    }\n",
    "\n",
    "with open('full_cities_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(full_cities_dict, f)\n",
    "\n",
    "with open('short_cities_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(short_cities_dict, f)\n",
    "    \n",
    "with open('PIT_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(PIT_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
